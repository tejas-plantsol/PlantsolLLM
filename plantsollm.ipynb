{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_db = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openpyxl as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xl.load_workbook(\"./data/collated/faolex_download.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb[wb.sheetnames[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_files(ws):\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            try:\n",
    "                target = cell.hyperlink.target\n",
    "                if target.startswith(\"https://faolex.fao.org/docs/pdf\"):\n",
    "                    pdf_res = requests.get(target)\n",
    "                    with open(f\"./data/raw/pdfs/{target.replace('https://faolex.fao.org/docs/pdf/', '')}\", \"wb\") as f:\n",
    "                        f.write(pdf_res.content)\n",
    "                        print(f\"Downloaded: {target}\")\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    downloaded = os.listdir(\"./data/raw\")\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            try:\n",
    "                target = cell.hyperlink.target\n",
    "                if not target.startswith(\"http://www.fao.org/faolex\") and target.replace(\"https://faolex.fao.org/docs/pdf/\", \"\") not in downloaded:\n",
    "                    htm_res = requests.get(target)\n",
    "                    with open(f\"./data/raw/htms/{target.replace('https://faolex.fao.org/docs/html/', '')}\", \"wb\") as f:\n",
    "                        f.write(htm_res.content)\n",
    "                        print(f\"Downloaded: {target}\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_all_files(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdfs = []\n",
    "for file in os.listdir(\"./data/raw/pdfs\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_loader = PyPDFLoader(f\"./data/raw/pdfs/{file}\")\n",
    "        pdf = pdf_loader.load()\n",
    "        pdf = [p.page_content for p in pdf]\n",
    "        pdfs.append({\"fname\": file.replace(\".pdf\", \"\"), \"text\": pdf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "htms = []\n",
    "for file in os.listdir(\"./data/raw/htms\"):\n",
    "    htm_loader = UnstructuredHTMLLoader(f\"./data/raw/htms/{file}\")\n",
    "    htm = htm_loader.load()\n",
    "    htm = [h.page_content for h in htm]\n",
    "    htms.append(htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=40) # Apx. 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = [\"\".join(p) for p in pdfs]\n",
    "htms = [\"\".join(h) for h in htms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_format_document(chain, document):\n",
    "    return chain.invoke(f\"Format the following document into one that is cleaner by removing formatting errors and unecessary special characters. Make it readable. Here is the document:\\n{document}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs_clean = []\n",
    "htms_clean = []\n",
    "printed = 0\n",
    "# for p in pdfs: \n",
    "#     try:\n",
    "#         pdfs_clean.append(gpt_format_document(chain, p[\"text\"]))\n",
    "#     except Exception as e:\n",
    "#         pdfs_clean.append(p[\"text\"])\n",
    "#         print(e)\n",
    "#     printed += 1\n",
    "#     print(f\"Cleaned: {printed}\")\n",
    "with open(\"./pdfs_clean1.txt\") as f:\n",
    "    pdfs_clean = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs_clean = [p[1:-1] for p in pdfs_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdfs)-len(pdfs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_index in range(len(pdfs_clean)):\n",
    "    if pdfs_clean[p_index] in pdfs:\n",
    "        temp_pdf = pdfs_clean[p_index]\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        encoded = encoding.encode(temp_pdf)\n",
    "        temp_formatted = []\n",
    "        for j in range(0, len(encoded), 15000): \n",
    "            temp_formatted.append(gpt_format_document(chain, encoding.decode(encoded[j:j+15000])))\n",
    "        pdfs_clean[p_index] = \" \".join(temp_formatted)\n",
    "        print(f\"Done with {p_index}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs_split = [splitter.create_documents([p]) for p in pdfs_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdfs_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=\"d42f1895-2cea-49a9-b83a-baeb8fef8f57\") # Was having issues with using dotenv variable for this, so I just pasted it into my code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"law\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = []\n",
    "for split_index in range(len(pdfs_split)):\n",
    "    fname = pdfs[split_index]\n",
    "    docs = pdfs_split[split_index]\n",
    "    for doc in docs:\n",
    "        total_docs.append({\"content\": doc.page_content}) # May need to add other metadata later, so I have created separate arrays total_docs and total_docs_content_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs_content_only = [d[\"content\"] for d in total_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(total_docs_content_only), 2000):\n",
    "    all_embeddings.append(client.embeddings.create(input=total_docs_content_only[i:i+2000], model=\"text-embedding-3-small\"))\n",
    "    time.sleep(60) # Timeout for OpenAI embedding rate limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in all_embeddings:\n",
    "    d = i.data\n",
    "    for e in d:\n",
    "        to_add.append(\n",
    "            {\n",
    "                \"id\": str(counter),\n",
    "                \"values\": e.embedding,\n",
    "                \"metadata\": {\n",
    "                    \"content\": total_docs_content_only[counter]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(to_add), 100):\n",
    "    index.upsert(to_add[i:i+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"If I want to spray pesticides on my farm in California but do not do so regularly, do I have to pay a fee to get my license?\"\n",
    "# hyde = chain.invoke(f\"Write a law-style response to the following question: {prompt}\")\n",
    "query = client.embeddings.create(input=prompt, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = query.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ids = [r[\"id\"] for r in results[\"matches\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_results = index.fetch(results_ids)[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_results\n",
    "content = [fetch_results[k][\"metadata\"][\"content\"] for k in dict.keys(fetch_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(f\"A user asked the following question: {prompt}{newline}Using the following documents as context, respond to the question. Avoid providing overly-technical answers and instead focus on the main context.{newline}{newline.join(content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    return np.dot(np.array(v1), np.array(v2))/(norm(np.array(v1))*norm(np.array(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838699100999074\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim([1, 2], [3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is no longer needed thanks to Ragas.\n",
    "# def answer_relevance(response, actual_question, n=5):\n",
    "#     generated_questions = json.loads(client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": f\"Generate {n} questions that a farmer might ask that would have the following response: {response}\"}], tools=tools).choices[0].message.tool_calls[0].function.arguments)[\"questions\"]\n",
    "#     generated_embeddings = client.embeddings.create(input=generated_questions, model=\"text-embedding-3-small\")\n",
    "#     actual_embeddings = client.embeddings.create(input=actual_question, model=\"text-embedding-3-small\")\n",
    "#     mean_cosine = sum([cosine_sim(generated_embeddings.data[i].embedding, actual_embeddings.data[0].embedding) for i in range(len(generated_embeddings.data))])/len(generated_embeddings.data)\n",
    "#     return mean_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = {\n",
    "    \"question\": [prompt],\n",
    "    \"answer\": [response],\n",
    "    \"contexts\": [content]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If I want to spray pesticides on my farm in Ca...</td>\n",
       "      <td>If you are not regularly engaged in the busine...</td>\n",
       "      <td>[the matter may proceed to hearing as though t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... answer_relevancy\n",
       "0  If I want to spray pesticides on my farm in Ca...  ...         0.905619\n",
       "\n",
       "[1 rows x 5 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[faithfulness, answer_relevancy])\n",
    "score.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
